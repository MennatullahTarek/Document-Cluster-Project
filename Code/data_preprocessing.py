# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lO8GwySYd03tuDySzpGemu_jqcmoDexW

$$ Text Cleaning \space and  \space Preprocessing. $$

---
# `#` Import Necessary Libraries
"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

"""---
# `#` Preprocess
"""

def preprocess_text(text):
    """Cleans and preprocesses text data."""
    text = text.lower()
    text = re.sub(r'\W', ' ', text)
    tokens = word_tokenize(text)
    tokens = [t for t in tokens if t not in stopwords.words('english')]
    lemmatizer = WordNetLemmatizer()
    return ' '.join([lemmatizer.lemmatize(t) for t in tokens])